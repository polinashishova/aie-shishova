# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (12000 строк, 9 столбцов)
- Признаки: присутствуют только числовые
- Пропуски: нет
- "Подлости" датасета: особых "подлостей" не было, признаки в разных масштабах, относительно немаленькое количество признаков (9 вместе с sample_id)

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (8000 строк, 4 столбцов)
- Признаки: присутствуют только числовые
- Пропуски: нет
- "Подлости" датасета: наличие шумовых данных и нелинейная структура данных

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: (15000 строк, 5 столбцов)
- Признаки: присутствуют только числовые
- Пропуски: нет
- "Подлости" датасета: наличие шума, а также различная плотность данных

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг: scaling с помощью StandardScaler
- Поиск гиперпараметров:
  - `ks = np.arange(2, 16)` для KMeans и иерархической кластеризации
  - `eps = np.linspace(0.1, 10, 10)`
  - `min_samples = np.arange(4, 100, 20)` для DBSCAN
  - `linkages = ['single', 'average', 'ward']` для иерархической кластеризации
  - при выборе "лучшего" руководствовалась графиками метрик в зависимости от количества кластеров, смотрела на все сразу: на пики silhouette и Calinski-Harabasz и "ямы" на графиках Davies-Bouldin
- Метрики: silhouette / Davies-Bouldin / Calinski-Harabasz, для DBSCAN при наличии шума учитывались только не шумовые точки
- Визуализация: PCA(2D) и t-SNE (`perplexity=15`, `learning_rate='auto'`, `max_iter=500`)

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

Минимум (для каждого датасета):

- KMeans (поиск `k`, фиксировала `random_state`, `n_init=10`)
- DBSCAN (`eps`, `min_samples`)
- AgglomerativeClustering (`k`, `linkage`)

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: KMeans c `{'k': 3}`
- Метрики (silhouette / DB / CH): 'silhouette': 0.39675785208949865,
                                  'davies_bouldin': 0.9646042500366256,
                                  'calinski_harabasz': 10446.638111140073
- Данное решение выглядит разумным для данного датасета, потому что показывает хорошие внутренние метрики по сравнению с другими вариантами

### 4.2 Dataset B

- Лучший метод и параметры: иерархическая кластеризация c `{'n_clusters': 3, 'linkage': 'ward'}`
- Метрики (silhouette / DB / CH): 'silhouette': 0.20763735890314128,
                                  'davies_bouldin': 1.3111375348939511,
                                  'calinski_harabasz': 2299.9172003357685
- Данное решение выглядит разумным для данного датасета, потому что показывает хорошие внутренние метрики и хорошо разделяет данные, а также хорошо работает с шумом и линейно неразделимыми данными

### 4.3 Dataset C

- Лучший метод и параметры: иерархическая кластеризация c `{'n_clusters': 4, 'linkage': 'ward'}`
- Метрики (silhouette / DB / CH): 'silhouette': 0.3035720503661607,
                                  'davies_bouldin': 1.1730948913052048,
                                  'calinski_harabasz': 6206.351567152033
- Данное решение выглядит разумным для данного датасета, потому что показывает хорошие внутренние метрики, а также справляется с разделением данных с разной плотностью

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- Где KMeans "ломается" и почему? Ломается, когда появляются линейно неразделимые структуры и шум.
- Где DBSCAN/иерархическая кластеризация выигрывают и почему? DBSCAN основан на плотности данных, так что для него не критичка "кучковатость" данных, как для KMeans, а иерархическая кластеризация выигрывает за счет того, что объединяет кластеры, которые находятся ближе всего друг к другу.
- Что сильнее всего влияло на результат (масштабирование, выбросы, плотность, пропуски, категориальные признаки)? В данном случае на результат значительно повлияло масштабирование, выбросы и плотность данных.

### 5.2 Устойчивость (обязательно для одного датасета)

- Какую проверку устойчивости делали: 5 запусков KMeans по разным seed и сравнение ARI на первом датасете с разделением на 3 кластера.
- При каждом запуске с разными seeds метки кластеров выходили одними и теми, что означает, что алгоритм успешно прошел проверку на устойчивость.
- Вывод: устойчиво, изменение seed не меняет результат вообше.

### 5.3 Интерпретация кластеров

- Кластеры были интерпретированы по среднему значению признаков по кластерам.

Dataset A: Кластер 0 и 1 представляют собой две противоположные крайности в данных, когда как кластер 2 — "золотая середина".

Dataset B: Алгоритм выделил 3 группы с разным уровнем шума: кластер 0: относительно стабильные объекты; кластер 1: объекты с высокой неопределенностью; кластер 2: определенные объекты с минимальным шумом.

Dataset C: Кластеры образуют четкие квадранты в пространстве (x1, x2):
- Кластер 0: левый верхний квадрант
- Кластер 1: правый нижний квадрант  
- Кластер 2: правый верхний квадрант (самые высокие значения)
- Кластер 3: левый нижний квадрант (самые низкие значения)

f_corr коррелирует с положением: правые квадранты имеют положительные значения,
левые — отрицательные.

## 6. Conclusion

Масштабирование — обязательный шаг для дистанционных алгоритмов, иначе признаки с большим разбросом будут доминировать.

Нет серебряной пули: каждый алгоритм имеет свои сильные стороны.

Внутренние метрики (silhouette, DB, CH) — необходимый, но недостаточный инструмент. Они помогают сравнивать модели и выбирать гиперпараметры, но обязательно нужна визуализация (PCA, t-SNE), чтобы убедиться, что кластеры выглядят осмысленно и соответствуют структуре данных, однако с визуализацией нужно быть осторожным, так как есть риск переинтерпретировать результаты (особенно t-SNE).

Интерпретация результатов — ключевой этап. Без него кластеризация остаётся чёрным ящиком. Профилирование кластеров по средним значениям признаков помогает понять, что на самом деле выделил алгоритм, и придать результатам практический смысл.

Качество кластеризации сильно зависит от природы данных (линейная разделимость, наличие шума, плотность, выбросы). Поэтому важно пробовать несколько алгоритмов и сравнивать их на одних и тех же метриках и визуализациях.

Корректный протокол unsupervised-эксперимента должен включать: препроцессинг (масштабирование), выбор диапазонов гиперпараметров для каждого алгоритма, оценку по нескольким внутренним метрикам, визуальную проверку, интерпретацию кластеров.