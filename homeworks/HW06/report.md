# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-04.csv`
- Размер: (25000 строк, 62 столбцов)
- Целевая переменная: `target` (2 класса: 0 и 1, соотношение 95% к 5%, сильный дисбаланс)
- Признаки: все признаки числовые, все кроме столбца id - вещественные

## 2. Protocol

- Разбиение: train/test (`test_size=0.2`, выборки стратифицированы по классам, `random_state=42`)
- Подбор: CV на train (5 фолдов, оптимизировалась метрика average precision)
- Метрики: accuracy, precision, recall, F1, ROC-AUC, average precision (и почему эти метрики уместны именно здесь), precision, recall, F1, average precision позволяют трезво оценить качество классификации в случае сильного дисбаланса классов

## 3. Models

Опишите, какие модели сравнивали и какие гиперпараметры подбирали.

Минимум:

- DummyClassifier
- LogisticRegression (с StandardScaler и подбором гиперпараметров (C и solver))
- DecisionTreeClassifier (с подбором гиперпараметров (`max_depth`, `mean_samples_leaf`, `cpp_alpha`) для регуляризации)
- RandomForestClassifier (также с подбором гиперпараметров (`max_depth`, `max_features`, `min_samples_leaf`))
- HistGradientBoostingClassifier (с подбором `learning_rate`, `max_depth`, `max_leaf_nodes`)
- StackingClassifier, полученный из комбинации моделей с лучшими по перебору параметрами (LogisticRegression, RandomForestClassifier, HistGradientBoostingClassifier) и метамоделью LogisticRegression

## 4. Results

- Таблица финальных метрик на test по всем моделям:

| #  | Model                          | Accuracy | Precision | Recall  | F1-score | ROC AUC | Avg Precision |
|----|--------------------------------|----------|-----------|--------|----------|---------|---------------|
| 5  | StackingClassifier             | 0.9822   | 0.9645    | 0.6626 | 0.7855   | 0.8991  | 0.7962        |
| 4  | HistGradientBoostingClassifier | 0.9804   | 0.9805    | 0.6138 | 0.7550   | 0.8987  | 0.7914        |
| 3  | RandomForestClassifier         | 0.9720   | 1.0000    | 0.4309 | 0.6023   | 0.8954  | 0.7679        |
| 2  | DecisionTreeClassifier         | 0.9650   | 0.7669    | 0.4146 | 0.5383   | 0.8185  | 0.5390        |
| 1  | LogisticRegression             | 0.9632   | 0.9079    | 0.2805 | 0.4286   | 0.8339  | 0.5088        |
| 0  | DummyClassifier                | 0.9050   | 0.0364    | 0.0366 | 0.0365   | 0.4933  | 0.0487        |


- Победитель по average precision:
Лучшей оказалась модель стекинга. Хотя бустинг по ключевой метрике не сильно ниже стекинга. Average precision у StackingClassifier самая высокая (0.7962), что логично, так как Stacking объединяет сильные стороны разных моделей (LogisticRegression, RandomForestClassifier, HistGradientBoostingClassifier), которые кстати также показывают хорошие результаты по AP.

## 5. Analysis

- Устойчивость: что будет, если поменять `random_state` (хотя бы 5 прогонов для 1-2 моделей) – кратко
Проверка устойчивости была проведена на 5 моделях (всех, кроме DummyClassifier), и ни какую модель значительно изменение `random_state` не повлияло. Максимальный разброс ключевой метрики у HistGradientBoostingClassifier и равен 0.0153.

- Ошибки: confusion matrix для лучшей модели + комментарий
| True \ Pred | 0             | 1            |
| ----------- | ------------- | ------------ |
| 0           | 4748 (0.9496) | 6 (0.0012)   |
| 1           | 83 (0.0166)   | 163 (0.0326) |

По матрице ошибок видно, что модель правильно угадывает целых 3.26% объектов положительного класса. Учитывая, что изначально положительных примеров всего лишь почти 5%, это неплохой результат.

- Интерпретация: permutation importance (top-10/15)
![importance](artifacts/figures/importances.png)
Наиболее важны по permutation importance первые 6-10 признаков на графике, остальные влияют на выбранную метрику (average precision) не так незначительно.

## 6. Conclusion

3-6 коротких тезисов: что вы поняли про деревья/ансамбли и про честный ML-протокол.

Деревья хорошо моделируют нелинейные зависимости, их легко интерпретировать, но легко переобучаются. Их переобучение можно регулировать двумя способами: ставить ограничения на рост дерева и обрезать дерево уже после того, как оно полностью построилось.

Ансамбль - модель, которая так или иначе объединяет несколько "слабых" моделей и на их основе становится одной сильной моделью. Беггинг - параллельное объединение одинаковых моделей, бустинг - последовательное объединение одинаковых моделей, а стекинг - объединение нескольких разнородных моделей.

Кросс-валидация с правильной стратификацией и раздельной калибровкой гарантирует честную оценку. Метрики для сильно несбалансированных данных (например, Average Precision) отражают реальное качество модели лучше, чем точность.