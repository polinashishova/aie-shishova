# Заметки по безопасности для проектов по инженерии ИИ

Этот файл дополняет `SECURITY.md` в студенческом репозитории и даёт **практические ориентиры**, что считать «минимальной гигиеной безопасности» для проектов по курсу.

Фокус: учебные проекты, работающие локально или в простом окружении (venv/Docker), но с прицелом на реальные практики.

---

## 1. Зачем думать про безопасность даже в учебном проекте

Даже учебный ИИ-проект:

- работает с **данными** (потенциально чувствительными);
- поднимает **сервис** (API, веб-интерфейс, CLI);
- использует **сторонние библиотеки и модели**;
- хранится в **публичном репозитории**.

Если этим пренебречь, можно:

- случайно «утечь» персональные данные или секреты;
- выложить в открытый доступ ключи от реальных сервисов;
- создать демонстрацию, которую нельзя показывать в реальной компании.

Цель этих заметок — помочь **не накосячить по-крупному** и показать, как выглядит базовая безопасность в инженерии ИИ.

---

## 2. Данные и приватность

### 2.1. Какие данные использовать

В рамках курса допустимы:

- открытые датасеты;
- синтетические данные;
- обезличенные данные, подготовленные для учебных целей.

Нельзя (без отдельного формального согласования):

- реальные персональные данные третьих лиц (ФИО, телефоны, e-mail, адреса, паспортные данные и т.п.);
- рабочие/коммерческие данные, покрытые NDA;
- медицинские и иные чувствительные данные.

Если сомневаешься, можно ли использовать какой-то датасет — по умолчанию считаем, что **нельзя**, пока не получили явное разрешение и не обезличили.

### 2.2. Что значит «обезличить»

Минимальный подход в учебном проекте:

- удалить/замаскировать:
  - имена, телефоны, адреса, e-mail, ID документов;
- заменить на:
  - абстрактные идентификаторы (`user_001`, `user_002`);
  - генеративные или случайные значения с тем же форматом (например, псевдотелефоны `+7 900 000-00-00`).

Важно: «убрать ФИО, но оставить уникальные комбинации полей» — всё ещё может быть рискованно. Для курса лучше использовать либо уже обезличенные, либо синтетические данные.

### 2.3. Логи, ноутбуки и «случайный слив»

Частая проблема: чувствительные данные попадают:

- в логи (`print`, logging);
- в HTML-экспорты ноутбуков;
- в скриншоты и презентации.

Минимальные меры:

- не логировать целиком «сырые» записи с персональными полями;
- для демонстраций и отчётов использовать:
  - подвыборку;
  - уже обезличенные/синтетические примеры;
- перед коммитом ноутбуков смотреть, **что именно** остаётся в выводе.

---

## 3. Секреты и доступы

### 3.1. Что такое «секрет» в проекте

Секреты — это любые данные, которые дают доступ к чему-то важному:

- пароли к базам данных;
- API-ключи внешних сервисов;
- токены доступа к облакам, GitHub, Telegram-ботам и т.п.;
- приватные ключи.

Принцип: если это даёт доступ к чему-то за пределами твоего ноутбука — это секрет.

### 3.2. Где секретам жить (и где не жить)

**Никогда:**

- не хардкодить секреты в код (`API_KEY = "..."`);
- не коммитить `.env` с реальными значениями;
- не писать токены в README, ноутбуки, скриншоты.

**Где можно:**

- в `.env` файле локально (но он в `.gitignore`);
- в переменных окружения;
- в секретах CI/CD (если такое используется).

Рядом в репозитории — только шаблон `.env.example` с описанием необходимых переменных.

### 3.3. Что делать, если секрет «утёк»

Если случайно закоммитил токен/пароль и запушил:

1. Считай его **скомпрометированным**, даже если быстро удалил.
2. **Отозвать/поменять** секрет:
   - перевыпустить токен;
   - поменять пароль/ключ.
3. Удалить его из репозитория:
   - убрать из кода/конфигов;
   - закоммитить изменение;
   - при необходимости — переписать историю, но для курса достаточно отзыва ключа.

Вывод: главный шаг — не пытаться «спрятать» секрет постфактум, а **немедленно его отозвать**.

---

## 4. Безопасность API-сервиса

### 4.1. Что не должен делать учебный API

Даже локальный учебный сервис не должен:

- исполнять произвольный код, присланный пользователем (eval/exec, shell-команды);
- отдавать наружу стэктрейсы с подробными деталями окружения;
- отдавать полные дампы входных данных в ответах (особенно если там могут быть чувствительные поля).

### 4.2. Валидация входных данных

Минимальный уровень:

- использовать схемы (pydantic/FastAPI) для описания входных структур;
- проверять типы и диапазоны (например, длину строки, диапазоны чисел);
- аккуратно обрабатывать пустые и некорректные запросы:
  - возвращать понятную ошибку (400/422);
  - не падать с 500 и стэктрейсом.

Правило: **никогда не доверяем входу**, даже если «это учебный пример» — всё равно полезно привыкать к валидации.

### 4.3. Ошибки и сообщения

- внешнему клиенту → короткие, нейтральные ошибки (`"invalid input"`, `"internal error"` без деталей);
- подробности (стэктрейсы, параметры) → только в логах, а не в ответе API.

---

## 5. Зависимости и supply chain

### 5.1. Библиотеки

Зависимости в ML-проекте — это тоже зона риска:

- уязвимости в веб-фреймворках/библиотеках;
- подменённые пакеты («typosquatting»: `scikitlearn` вместо `scikit-learn`).

Минимальные меры:

- внимательно смотреть на имена пакетов в `requirements.txt`;
- не ставить пакеты из неизвестных форков/репозиториев «просто по ссылке»;
- по возможности фиксировать конкретные версии, если они уже оттестированы.

### 5.2. Файлы и модели из интернета

Осторожно относиться к:

- скриптам, которые скачиваются и тут же исполняются;
- бинарным артефактам (чужие `.pkl`, веса моделей, исполняемые файлы).

Для курса достаточно:

- использовать проверенные источники (официальные репозитории, well-known библиотеки);
- не запускать «магические» скрипты из непонятных Gist’ов/форков.

---

## 6. Риски, специфичные для ИИ-моделей

### 6.1. Дрейф и «сломанные» предсказания

Даже в учебном сервисе можно:

- столкнуться с изменением распределения данных;
- получить странные/неадекватные ответы модели.

Минимум:

- иметь базовый мониторинг входов/выходов (хотя бы логировать аггрегированные показатели);
- не доверять модели архитектурно «как оракулу», а помнить, что это статистическая система.

### 6.2. Входные атаки и prompt-injection (для LLM/RAG/агентов)

Если проект связан с LLM:

- нельзя верить входным промптам;
- нужно:
  - фильтровать/ограничивать команды, которые модель может «протащить»;
  - не давать модели прямой доступ к файловой системе/сетевым ресурсам без контроля.

На уровне курса:

- показывать, что есть риск prompt-injection;
- не строить сценариев вида «LLM может делать всё, что захочет» без жёстких ограничений.

---

## 7. Локальная среда, репозитории и шаринг

### 7.1. Публичные репозитории

Если репозиторий публичный:

- всё, что в нём лежит, **считай общедоступным**;
- особенно аккуратно:
  - с данными;
  - с конфигами;
  - с логами;
  - с документацией, где могут мелькать реальные URL/ID.

### 7.2. Скриншоты, презентации, отчёты

Перед тем как что-то «показать миру»:

- убрать/замазать реальные токены, пароли, ID;
- убедиться, что на скриншотах нет «кусочка продакшена» или внутренних систем.

### 7.3. Использование внешних ИИ-ассистентов

Если использешь внешние ИИ-сервисы для помощи:

- **не копируй** туда реальные секреты и чувствительные данные;
- либо:
  - обезличивай данные;
  - либо используй синтетические примеры.

---

## 8. Мини-чеклист безопасности перед сдачей проекта

Пройдись по этим пунктам:

1. **Данные**
   - нет «живых» персональных или NDA-данных в репозитории;
   - все примеры в ноутбуках/отчёте — обезличенные или синтетические.

2. **Секреты**
   - в репозитории **нет** токенов, паролей, ключей;
   - есть `.env.example`, а реальный `.env` в `.gitignore`;
   - при случайном сливе секрет **заменён/отозван**.

3. **API и сервис**
   - входные данные валидируются;
   - ошибки не возвращают наружу стэктрейсы и внутренние детали;
   - есть `/health` или аналогичный простой health-check.

4. **Зависимости**
   - `requirements.txt` не содержит подозрительных пакетов;
   - используемые библиотеки — из нормальных источников, без «левых» форков.

5. **Модели и ИИ-логика**
   - нет опасных «eval/exec» на пользовательском вводе;
   - для LLM/агентных сценариев явно ограничены возможности и описаны риски.

6. **Репозиторий и шаринг**
   - публичный репозиторий не содержит того, что нельзя показывать;
   - скриншоты и отчёты не содержат токенов/реальных данных.

Если на большинство пунктов ответ «да», то твой проект находится на хорошем уровне базовой безопасности для учебного курса по инженерии ИИ — и не стыдно будет показывать его как демонстрацию инженерной зрелости.

---
