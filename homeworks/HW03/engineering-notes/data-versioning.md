# Версионирование данных и моделей

Эта заметка про то:

- почему в ИИ-проектах **нельзя** ограничиться только Git для кода;
- как минимально, по-курсовому, версионировать данные и модели;
- что такое DVC/аналогичные инструменты и когда о них стоит задуматься.

---

## 1. Зачем вообще версионировать данные и модели

Для кода Git уже решает почти всё. Но в ИИ-проекте есть ещё:

- **данные**: сырые, очищенные, фичи, сплиты train/val/test;
- **модели**: разные эксперименты, чекпоинты, финальные версии;
- **артефакты**: эмбеддинги, индексы, предобработанные фичи.

Без версионирования получается:

- «этот CSV немного другой, чем в прошлой версии, но я не помню чем»;
- «модель v2 вроде лучше, но я не знаю, на каких данных она училась»;
- «метрика в отчёте не воспроизводится, потому что сплит поменялся».

Цель версионирования:

> В любой момент понимать, **какая модель на каких данных и с какими настройками была обучена** — и уметь это повторить.

---

## 2. Мини-уровень для курсового проекта (без DVC)

Для курса достаточно **дисциплины + простых соглашений**.  

Базовая идея: разделить проект на:

- данные;
- эксперименты;
- модели;
- минимальные метаданные.

### 2.1. Структура папок

Пример для `project/`:

```text
project/
  data/
    raw/
    processed/
    splits/
  models/
    checkpoints/
    final/
  notebooks/
  src/
  configs/
````

Смыслы:

- `data/raw/` — исходные данные (по возможности — маленькие, учебные, обезличенные);
- `data/processed/` — очищенные/преобразованные данные, фичи;
- `data/splits/` — сохранённые разбиения train/val/test (например, индексы);
- `models/checkpoints/` — промежуточные чекпоинты;
- `models/final/` — финальные модели, которые используются в сервисе.

### 2.2. Явная фиксация версий в именах

Простейшая версия:

- `data/processed/train_v1.csv`
- `data/processed/train_v2.csv`
- `models/final/model_v1.pkl`
- `models/final/model_v2.pkl`

Где `v1`, `v2` — это **логические версии**, связанные с экспериментами.

Можно привязывать версии к дате:

- `model_2025-10-01.pkl`
- `features_2025-10-01.parquet`

Главное — чтобы в отчёте/ноутбуке было понятно, **какой файл к какому эксперименту относится**.

### 2.3. Миниметаданные: `metadata.json` / `README.md`

Очень помогает небольшой файл с описанием:

`project/models/final/README.md` (или `metadata.json`):

```markdown
# Финальные модели

- `model_v1.pkl`
  - дата обучения: 2025-10-01
  - данные: `data/processed/train_v1.csv`
  - конфиг: `configs/experiment_v1.yaml`
  - метрики: ROC-AUC 0.81 на валидации, 0.79 на тесте

- `model_v2.pkl`
  - дата обучения: 2025-10-10
  - данные: `data/processed/train_v2.csv`
  - конфиг: `configs/experiment_v2.yaml`
  - метрики: ROC-AUC 0.84 на валидации, 0.83 на тесте
  - используется в сервисе `/predict`
```

Такой файл уже делает проект намного более воспроизводимым, даже без тяжёлых инструментов.

---

## 3. Как связать данные, конфиги, эксперименты и модели

Минимальный паттерн:

1. **Конфиг эксперимента**
   Например, `configs/experiment_v2.yaml`:

   - какие данные используются;
   - какие признаки/фильтры включены;
   - гиперпараметры модели;
   - информация о сплите train/val/test.

2. **Код обучения**
   Сохранить:

   - конфиг в артефакты эксперимента (копировать рядом с моделью);
   - модель в `models/checkpoints/` или `models/final/`.

3. **Логика именования**
   Конфиг, модель и набор данных должны быть **связаны по имени**:

   - `experiment_v2.yaml`
   - `train_v2.csv`
   - `model_v2.pkl`

4. **Отчёт/ноутбук**
   В `report.md` или ноутбуке явно писать:

   - «Эксперимент v2: использовали `train_v2.csv`, конфиг `experiment_v2.yaml`, модель `model_v2.pkl`».

Это уже полноценное **ручное версионирование**: мы можем вернуться к нужной связке «данные + конфиг + модель».

---

## 4. Роль Git в версионировании данных

Git можно использовать для **маленьких и средних** артефактов:

- скрипты подготовки данных (`src/data/...`);
- сами конфиги (`configs/experiment_v2.yaml`);
- мелкие датасеты/выборки (десятки килобайт / несколько мегабайт);
- маленькие модели.

Важно:

- не коммитить гигабайты сырых данных;
- не коммитить огромные чекпоинты десятками версий.

Если файлы начинают быть большими — смотри `git-lfs.md` и думай, действительно ли это должно быть в репозитории.

---

## 5. DVC и другие системы версионирования данных (на будущее)

DVC (Data Version Control) и аналоги:

- позволяют вести версионирование данных и моделей **похожим на Git образом**;
- хранят большие файлы в внешних хранилищах (S3, локальное хранилище, on-prem storage);
- используют маленькие «метаданные» в Git, чтобы описать, где лежит какая версия данных/модели.

Базовая идея DVC:

- в репозитории лежат `.dvc`-файлы + конфиги пайплайнов;
- сами данные — в отдельном хранилище;
- можно сказать: «дай мне версию данных/моделей для этого коммита» — и восстановить состояние.

Для курса:

- **необязательно** использовать DVC;
- достаточно аккуратной структуры папок и явных метаданных;
- но полезно знать, что такой класс инструментов существует и используется «взрослыми» MLOps-командами.

---

## 6. Версионирование моделей в продакшен-подходе (реестры моделей)

В более зрелых системах:

- есть **реестр моделей** (Model Registry):

  - каждая модель имеет:

    - версию (`1`, `2`, `3`…),
    - статус (`staging`, `production`, `archived`),
    - привязку к данным и эксперименту;
- развертывание привязано не к файлу `model.pkl`, а к **версии модели в реестре**.

MLflow, Kubeflow, другие MLOps-платформы:

- хранят связи:

  - эксперимент → артефакты → модель → версия;
- позволяют откатываться к предыдущей версии модели;
- дают UI для просмотра метрик, артефактов, параметров.

В курсе достаточно:

- мини-реестра в виде `README.md`/`metadata.json` в `models/`;
- чёткого описания в `report.md`, **какая версия модели сейчас используется**.

---

## 7. Мини-чеклист по версионированию данных и моделей для проекта

Перед защитой проекта посмотри на свой репозиторий и задай себе вопросы:

1. Понимаю ли я, **какие данные** использовались для обучения финальной модели?
2. Есть ли в `project/data/` разделение на `raw/`, `processed/`, `splits/` (или аналогичное логичное разделение)?
3. Могу ли я быстро сказать:

   - какой конфиг (`configs/...`) соответствует текущей использующейся в сервисе модели?
4. Есть ли в `project/models/` **понятные имена** файлов моделей (`model_v1`, `model_v2` и т.п.), а не просто `model.pkl`?
5. Задокументировано ли в `report.md` или `models/README.md`:

   - какая версия модели и данных используется в `/predict`;
   - какие метрики у этой версии;
   - чем она отличается от предыдущей?

Если на эти вопросы можно ответить «да» — твой уровень версионирования очень неплох для курсового проекта по инженерии ИИ.

Если нет — начни хотя бы с:

- аккуратной структуры папок;
- явных имён файлов с версиями;
- короткого README с описанием того, как данные и модели связаны между собой.

---
