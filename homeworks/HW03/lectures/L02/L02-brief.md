# Лекция 02 – Данные и признаки: сбор, очистка, валидация, DataOps

Неделя: 02
Формат: лекция про данные, признаки и DataOps; переход от системного взгляда к практической работе с данными

---

## О чём эта лекция

Эта лекция фокусирует внимание на «материале» для ИИ-систем – данных и признаках. Мы переходим от общей архитектурной картинки к конкретным источникам данных, их свойствам и ограничениям, а также показываем, почему качество данных задаёт потолок качества модели, независимо от архитектуры.

Разбираются основные типы источников (OLTP-БД, DWH/витрины, логи и события, файлы, внешние API, стриминговые платформы) и их компромиссы: структура, скорость, объёмы, стабильность, юридические и инфраструктурные риски. На примере онлайн-сервиса такси иллюстрируется, какие данные вообще могут быть доступны и какие из них реально полезны для ML.

Вводится инженерное понятие качества данных: измерения (полнота, целостность, уникальность, актуальность, валидность, точность), примеры нарушений и то, как дефекты данных ломают обучение и инференс. На основе примера «грязного» датафрейма показывается, как типичные проблемы (дубли, пропуски, некорректные диапазоны, битые даты и категориальные значения) превращаются в конкретные проверки.

Далее обсуждается подход «validation as code»: проверки качества данных рассматриваются как полноценный артефакт (код + отчёты), а не как разовые ручные действия. Через простой пайплайн показывается разделение слоёв `data/raw`, `data/processed` и `data/features`, а также роль gate-критериев приёмки.

Во второй части лекции фокус смещается на признаки: базовые понятия (объект, признак, таргет), типы признаков, примеры для кейса онлайн-такси, типичные ошибки при работе с признаками и назначение «карточки признака» как артефакта, фиксирующего смысл, тип, диапазоны и правила расчёта признака в проекте.

---

## Ключевые идеи и опорные тезисы

1. **Данные задают потолок качества модели.** Даже лучшая архитектура не компенсирует систематические проблемы с данными: пропуски, смещения, неконсистентность, устаревание.

2. **Источники данных ≠ просто «таблички».** OLTP-БД, DWH, логи, файлы, внешние API и стриминговые платформы дают разные компромиссы по структуре, скорости, детализации и надёжности; эти свойства нужно учитывать ещё на этапе планирования ИИ-проекта.

3. **Качество данных – набор измерений, а не одно число.** Полнота, целостность, уникальность, актуальность, валидность и точность позволяют по-разному «пощупать» проблемы в датасете и затем превратить их в формальные проверки.

4. **Дефекты данных ломают и обучение, и прод.** Дубли, битые ссылки, неверные диапазоны, мусорные статусы и некорректные даты могут приводить к смещению оценок качества, нестабильным моделям и ошибкам в продакшене.

5. **От «посмотреть на глаз» к «validation as code».** Проверки должны быть воспроизводимым кодом с отчётами, а не одноразовым EDA в ноутбуке; это уменьшает количество сюрпризов и делает качество данных управляемым.

6. **Слои данных в проекте важны не меньше слоёв кода.** Разделение на `data/raw`, `data/processed` и `data/features` помогает отслеживать происхождение данных, повторять эксперименты и аккуратно внедрять новые источники.

7. **Gate на данных – такой же контроль, как тесты на код.** Перед тем как данные попадут в обучение или в прод-пайплайн, они должны пройти формализованные критерии приёмки; это снижает риск «тихого» деградационного дрейфа.

8. **Признаки – не просто «колонки в таблице».** Признак – это осмысленная величина с определённым способом вычисления, типом, диапазоном и бизнес-смыслом; от качества feature engineering часто зависит больше, чем от выбора модели.

9. **Карточка признака – ключевой артефакт для команды.** Явное описание признака (формула, источники, ограничения, ответственный) повышает воспроизводимость, облегчает дебаг и позволяет безопасно переиспользовать признаки в разных моделях.

10. **DataOps – инженерный подход к данным.** Практики версионирования, тестирования, мониторинга и автоматизации применимы не только к коду, но и к данным и их пайплайнам.

---

## Связь с мини-проектом и последующими неделями

### Мини-проект

- Лекция 02 задаёт основу для того, как в мини-проекте будут устроены **данные и признаки**: от хранения «сырых» выгрузок до формирования таблицы признаков для модели.
- В проекте потребуется организовать структуру `data/` (минимум: слои `raw`, `processed`, `features`) и не смешивать в одном месте грязные и подготовленные данные.
- На основе идей лекции вы будете **переводить измерения качества данных в конкретные проверки** (скрипты/функции), которые можно запускать перед обучением моделей.
- Понятие «карточки признака» ляжет в основу документации по признакам внутри репозитория проекта: вам нужно будет фиксировать смысл, тип и ограничения ключевых признаков, а не полагаться только на самоочевидные названия колонок.

### Связь с последующими лекциями

- Лекции, посвящённые **архитектуре хранилищ и озёр данных**, детализируют слои `raw/processed/features` и покажут, как это масштабируется до промышленных Data Lake / DWH и feature store.
- В блоке про **MLOps и продакшн-пайплайны** идеи «validation as code», gate-критериев и DataOps будут развиты до полноценных pipeline’ов обучения и инференса с автоматическими проверками и мониторингом.
- Лекции по **наблюдаемости и мониторингу моделей** добавят к метрикам качества модели метрики качества и распределений данных в проде, опираясь на ту же терминологию и подходы к валидации.
- В лекциях про **доверенный ИИ и риски** фокус на качестве данных будет расширен: к техническим проблемам добавятся смещения, дрейфы, этические и правовые ограничения на использование определённых полей и источников.

---

## Минимум, который студент должен забрать с собой

К концу Лекции 02 студенту важно:

1. Уметь **объяснить, почему качество данных важнее архитектуры модели**, приводя примеры типичных дефектов и их влияния на обучение/инференс.
2. Понимать различия между **источниками данных** (OLTP, DWH, логи, файлы, внешние API, стриминг) и уметь перечислить их ключевые плюсы и риски для ML-задач.
3. Различать слои **`data/raw`, `data/processed`, `data/features`** и уметь в общих чертах нарисовать пайплайн: от «сырых» данных через проверки и очистку к стабильной таблице признаков.
4. Понимать, что **валидация данных должна быть оформлена как код** с отчётами и критериями приёмки (gate), а не как одноразовая ручная проверка.
5. Чётко формулировать, что такое **объект, признак и таргет**, какие бывают типы признаков, и зачем проекту нужны **карточки признаков** как отдельный артефакт.

---
