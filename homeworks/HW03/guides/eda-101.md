# eda-101 – экспресс-анализ табличных данных (Pandas + графики)

## 1. Зачем нам EDA на курсе

Exploratory Data Analysis (EDA, разведочный анализ данных) – это первый обязательный шаг перед любыми моделями и “красивыми” алгоритмами.

На курсе EDA нужен для того, чтобы ты:

- **понимал, с чем работаешь**: размер, типы столбцов, диапазоны значений, пропуски, дубликаты;
- **умел быстро находить проблемы в данных**: пропущенные значения, выбросы, странные категории;
- **делал простые, но осмысленные визуализации**: распределения, зависимости между признаками, тренды;
- **формулировал выводы** на основе таблиц и графиков.

> Идея: EDA – это “обязательная разминка” перед любым моделированием, без которой легко построить красивую модель на мусорных данных.

На курсе предполагается, что **почти в каждой работе** с табличными данными есть хотя бы минимальный EDA-блок.

---

## 2. Предварительные знания и окружение

Перед EDA ты уже должен:

- запускать Jupyter-ноутбуки (см. `jupyter-101.md`);
- понимать основы Python (типовые конструкции, функции, импорт модулей – см. `python-101.md`);
- уметь работать с окружением проекта через `uv` (см. `uv-101.md`);
- комфортно чувствовать себя в терминале (см. `unix-101.md`).

Типичный старт для EDA в репозитории курса:

```bash
git clone <URL_репозитория>
cd <папка_репозитория>
uv sync
uv run jupyter lab
```

Дальше ты открываешь нужный ноутбук (например, `notebooks/eda.ipynb` или `homeworks/HW02/eda.ipynb`) и работаешь уже в браузере.

---

## 3. Типовой рабочий цикл EDA

Практически любой EDA у нас на курсе можно описать так:

1. **Подключить библиотеки**

   ```python
   import pandas as pd
   import matplotlib.pyplot as plt
   import seaborn as sns
   ```

2. **Загрузить данные**

   ```python
   df = pd.read_csv("data/input.csv")
   ```

3. **Посмотреть общую картину**

   - размеры, типы, первые/последние строки;
   - базовая статистика;

4. **Проверить качество данных**

   - пропуски;
   - дубликаты;
   - странные категории;

5. **Сделать несколько базовых графиков**

   - распределение ключевых признаков;
   - зависимость целевой переменной от признаков;

6. **Сформулировать выводы**

   - 3-7 коротких пунктов: что увидел, что будет влиять на подготовку данных и модель.

Важно: EDA – это не “потыкать графики”, а **осмысленный набор шагов**, ведущий к понятным выводам.

---

## 4. Загрузка и первичный осмотр данных

### 4.1. Загрузка из файлов

Минимум, который стоит уметь:

```python
import pandas as pd

# CSV
df = pd.read_csv("data/input.csv")

# Excel (если нужно)
# df = pd.read_excel("data/input.xlsx", sheet_name="Лист1")

# Parquet (если используется в проекте)
# df = pd.read_parquet("data/input.parquet")
```

### 4.2. Общая информация

Сразу после загрузки:

```python
df.shape          # (n_rows, n_cols)
df.head()         # первые 5 строк
df.tail()         # последние 5 строк
df.sample(5)      # случайные 5 строк

df.info()         # типы столбцов + количество ненулевых значений
df.describe()     # базовая статистика по числовым столбцам
```

Для категориальных признаков удобно использовать:

```python
df["city"].value_counts()
df["city"].value_counts(normalize=True)  # доли
```

---

## 5. Базовые операции Pandas, которые пригодятся почти везде

### 5.1. Выбор столбцов и фильтрация строк

```python
# Один столбец
ages = df["age"]

# Несколько столбцов
subset = df[["age", "height", "city"]]

# Фильтрация по условию
adults = df[df["age"] >= 18]

# Сложные условия (не забываем про скобки!)
moscow_adults = df[(df["age"] >= 18) & (df["city"] == "Moscow")]
```

### 5.2. Создание новых признаков

```python
df["bmi"] = df["weight_kg"] / (df["height_m"] ** 2)

# Логический признак
df["is_adult"] = df["age"] >= 18
```

### 5.3. Группировки и агрегаты

```python
# Средний возраст по городам
df.groupby("city")["age"].mean()

# Несколько агрегаций
df.groupby("city").agg(
    count=("age", "count"),
    mean_age=("age", "mean"),
    mean_height=("height", "mean"),
)

# Группировка по нескольким столбцам
df.groupby(["city", "gender"]).agg(
    mean_age=("age", "mean"),
    count=("age", "count"),
)
```

---

## 6. Пропуски и дубликаты

### 6.1. Пропущенные значения

Сначала – понять масштаб проблемы:

```python
df.isna().sum()        # количество пропусков по столбцам
df.isna().mean()       # доля пропусков по столбцам
```

Иногда удобно сразу собирать таблицу по пропускам:

```python
missing = (
    df.isna()
    .mean()
    .reset_index()
    .rename(columns={"index": "column", 0: "missing_share"})
)
missing.sort_values("missing_share", ascending=False, inplace=True)
missing
```

Частые операции:

```python
# Удалить строки, где есть пропуски в важных столбцах
df_clean = df.dropna(subset=["target", "age"])

# Заполнить пропуски средним (для числовых)
df["age_filled"] = df["age"].fillna(df["age"].mean())

# Заполнить пропуски константой (для категориальных)
df["city_filled"] = df["city"].fillna("UNKNOWN")
```

Важно: **на курсе достаточно объяснить, что и зачем ты сделал** с пропусками (удалил/заполнил/оставил).

### 6.2. Дубликаты

Проверка и удаление дубликатов:

```python
df.duplicated().sum()            # количество полностью дублирующих строк
df_no_dups = df.drop_duplicates()
```

Если нужно проверять дубликаты по части столбцов:

```python
df.duplicated(subset=["user_id"]).sum()
unique_users = df.drop_duplicates(subset=["user_id"])
```

---

## 7. Простая визуализация: распределения и зависимости

Для базового EDA на курсе достаточно уметь:

- построить распределения ключевых числовых признаков;
- посмотреть распределение целевой переменной;
- визуализировать связь между двумя признаками.

### 7.1. Подготовка (Matplotlib / Seaborn)

В начале ноутбука:

```python
import matplotlib.pyplot as plt
import seaborn as sns

# Опционально: стиль по умолчанию
sns.set()
```

> На курсе не требуется “художественное оформление” графиков. Важно, чтобы график читался и по нему можно было сделать вывод.

### 7.2. Распределение числового признака

```python
plt.figure()
sns.histplot(df["age"], bins=30, kde=True)
plt.title("Распределение возраста")
plt.xlabel("Возраст")
plt.ylabel("Частота")
plt.show()
```

### 7.3. Распределение категориального признака

```python
plt.figure()
sns.countplot(x="city", data=df)
plt.title("Распределение по городам")
plt.xticks(rotation=45)
plt.show()
```

### 7.4. Связь признака с целевой переменной

Пример: возраст vs. таргет:

```python
plt.figure()
sns.boxplot(x="target", y="age", data=df)
plt.title("Распределение возраста по классам целевой переменной")
plt.show()
```

Или scatter-plot:

```python
plt.figure()
sns.scatterplot(x="feature1", y="feature2", hue="target", data=df, alpha=0.5)
plt.title("Связь feature1 и feature2")
plt.show()
```

### 7.5. Матрица корреляций

```python
plt.figure()
corr = df.corr(numeric_only=True)
sns.heatmap(corr, annot=False, cmap="coolwarm", center=0)
plt.title("Корреляция числовых признаков")
plt.show()
```

---

## 8. Plotly и интерактивные графики (опционально)

Если в репозитории уже установлен Plotly, можно делать интерактивные графики:

```python
import plotly.express as px

fig = px.scatter(
    df,
    x="feature1",
    y="feature2",
    color="target",
    title="Интерактивный scatterplot",
)
fig.show()
```

Для курса Plotly **не является обязательным** инструментом. Главное – уметь строить базовые статические графики и делать по ним выводы.

---

## 9. EDA в домашках и проекте: что мы ожидаем

В типичной работе минимальный “нормальный” EDA-блок выглядит так:

1. **Загрузка и первичный осмотр**

   - код загрузки данных;
   - `df.shape`, `df.head()`, `df.info()`, `df.describe()`;
   - комментарий: что за данные, сколько строк/столбцов, какие основные столбцы.

2. **Пропуски и дубликаты**

   - `df.isna().sum()` / `df.isna().mean()` и `df.duplicated().sum()`;
   - простые решения: удалить, заполнить; пояснение, почему именно так.

3. **Базовая статистика по ключевым признакам**

   - `value_counts` для категориальных;
   - группировки `groupby` для интересных срезов.

4. **Несколько графиков**

   - распределение 1-2 ключевых признаков;
   - хотя бы одна картинка про связь признака с целевой переменной.

5. **Краткие выводы**

   - 3-7 пунктов в конце блока:

     - что интересного обнаружено;
     - какие проблемы в данных есть;
     - что ты собираешься делать при подготовке данных/обучении модели (например, “заполним пропуски в возрасте медианой”, “выбросим строки с нереалистичными значениями” и т.п.).

---

## 10. Частые ошибки и как их избежать

1. **“EDA без слов”**

   - Ноутбук полон графиков, но нет ни одного текстового комментария.
   - Что делать: после ключевых ячеек писать 1-3 предложения с выводами.

2. **Слишком мало EDA**

   - Только `df.head()` и сразу обучение модели.
   - Что делать: добавить анализ пропусков, простую статистику и хотя бы пару графиков.

3. **Слишком много кода без структуры**

   - 100+ ячеек с мелкими экспериментами, без логики.
   - Что делать: группировать шаги (загрузка → пропуски → дубликаты → графики → выводы), лишние эксперименты можно убирать перед сдачей.

4. **Смешивание EDA и тяжёлой обработки**

   - В блоке EDA уже идёт сложный препроцессинг, генерация множества признаков, “боевой” код.
   - Что делать: держать разведочный анализ отдельно, а финальную обработку – в коде подготовки данных/пайплайне.

5. **Воспроизводимость**

   - Ноутбук не запускается с нуля (`Restart & Run All` падает).
   - Что делать: перед сдачей обязательно проверять ноутбук через `Restart & Run All` (см. `jupyter-101.md`) и использовать `uv` для окружения.

---

## 11. Мини-чек-лист EDA перед сдачей

- [ ] Данные загружаются без ошибок.
- [ ] Показаны `shape`, `head`, `info`, `describe`.
- [ ] Есть анализ пропусков и дубликатов (с простыми решениями).
- [ ] Есть хотя бы 2-3 осмысленных графика.
- [ ] Есть группировки/сводные таблицы по ключевым признакам.
- [ ] В конце блока есть текстовые выводы.
- [ ] Ноутбук полностью запускается с нуля (`Restart & Run All`) при использовании `uv run jupyter lab`.

Если всё это выполняется, твой EDA-блок соответствует ожиданиям курса и даёт хорошую базу для дальнейшего моделирования.

---
